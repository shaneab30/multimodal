{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eef3aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc4baeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Load Speech Dataset\n",
    "# ----------------------------\n",
    "speech_dir = 'dataset/speech'\n",
    "speech_data = []\n",
    "\n",
    "for file in os.listdir(speech_dir):\n",
    "    if file.endswith('.wav'):\n",
    "        parts = file.split('_')\n",
    "        if len(parts) == 3:\n",
    "            word = parts[1]\n",
    "            emotion = parts[2].replace('.wav', '')\n",
    "            speech_data.append({\n",
    "                'word': word,\n",
    "                'emotion': emotion,\n",
    "                'speech_path': os.path.join(speech_dir, file)\n",
    "            })\n",
    "\n",
    "speech_df = pd.DataFrame(speech_data)\n",
    "speech_df.to_csv('speech_word_dataset.csv', index=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Load Text Dataset\n",
    "# ----------------------------\n",
    "def load_csvs_from_dir(directory):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(directory, file))\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "text_train_df = load_csvs_from_dir(\"dataset/text/train\")\n",
    "text_val_df = load_csvs_from_dir(\"dataset/text/validation\")\n",
    "text_test_df = load_csvs_from_dir(\"dataset/text/test\")\n",
    "text_df = pd.concat([text_train_df, text_val_df, text_test_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28ea854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Encode Labels (Shared)\n",
    "# ----------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = pd.concat([speech_df['emotion'], text_df['label']], ignore_index=True)\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "speech_df['label'] = label_encoder.transform(speech_df['emotion'])\n",
    "text_df['label'] = label_encoder.transform(text_df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e37fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Tokenizer and BERT Model\n",
    "# ----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63cbbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Feature Extraction Utils\n",
    "# ----------------------------\n",
    "def extract_mfcc(wav_path, max_len=100):\n",
    "    y, sr = librosa.load(wav_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0,0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc.T\n",
    "def extract_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=32)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "793f56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 6. Early Fusion Dataset\n",
    "# ----------------------------\n",
    "class EarlyFusionDataset(Dataset):\n",
    "    def __init__(self, speech_df, text_df):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Matching based on emotion class\n",
    "        min_samples = min(len(speech_df), len(text_df))\n",
    "        for i in range(min_samples):\n",
    "            speech_row = speech_df.iloc[i]\n",
    "            text_row = text_df.iloc[i]\n",
    "\n",
    "            # Extract features\n",
    "            mfcc = extract_mfcc(speech_row['speech_path'])  # shape: [time, 40]\n",
    "            bert = extract_bert_embedding(text_row['text'])  # shape: [768]\n",
    "\n",
    "            # Concatenate\n",
    "            bert_repeated = np.repeat(bert[np.newaxis, :], mfcc.shape[0], axis=0)  # [time, 768]\n",
    "            fused = np.concatenate((mfcc, bert_repeated), axis=1)  # [time, 808]\n",
    "\n",
    "            self.features.append(torch.tensor(fused, dtype=torch.float32))\n",
    "            self.labels.append(torch.tensor(speech_row['label'], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a2558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7. Collate Function for Padding\n",
    "# ----------------------------\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "    padded = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    return padded, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66e0dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 8. LSTM Model\n",
    "# ----------------------------\n",
    "class EarlyFusionLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=808, hidden_dim=128, num_classes=6):\n",
    "        super(EarlyFusionLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        return self.fc(hn.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c56382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.6080, Train Acc: 14.90%, Val Loss: 2.2680, Val Acc: 13.75%\n",
      "Epoch 2, Train Loss: 1.9985, Train Acc: 23.75%, Val Loss: 1.8813, Val Acc: 25.42%\n",
      "Epoch 3, Train Loss: 1.7655, Train Acc: 35.83%, Val Loss: 1.7273, Val Acc: 28.75%\n",
      "Epoch 4, Train Loss: 1.5863, Train Acc: 40.52%, Val Loss: 1.5450, Val Acc: 32.92%\n",
      "Epoch 5, Train Loss: 1.3947, Train Acc: 49.17%, Val Loss: 1.3769, Val Acc: 42.92%\n",
      "Epoch 6, Train Loss: 1.2066, Train Acc: 60.10%, Val Loss: 1.2248, Val Acc: 54.58%\n",
      "Epoch 7, Train Loss: 1.0489, Train Acc: 72.92%, Val Loss: 1.1236, Val Acc: 58.75%\n",
      "Epoch 8, Train Loss: 0.9059, Train Acc: 79.06%, Val Loss: 0.9956, Val Acc: 66.67%\n",
      "Epoch 9, Train Loss: 0.7615, Train Acc: 86.46%, Val Loss: 0.8629, Val Acc: 75.00%\n",
      "Epoch 10, Train Loss: 0.6059, Train Acc: 91.77%, Val Loss: 0.7086, Val Acc: 82.08%\n",
      "Epoch 11, Train Loss: 0.4448, Train Acc: 95.83%, Val Loss: 0.5274, Val Acc: 91.25%\n",
      "Epoch 12, Train Loss: 0.2899, Train Acc: 98.54%, Val Loss: 0.3679, Val Acc: 94.58%\n",
      "Epoch 13, Train Loss: 0.1893, Train Acc: 99.48%, Val Loss: 0.2804, Val Acc: 96.25%\n",
      "Epoch 14, Train Loss: 0.1295, Train Acc: 99.79%, Val Loss: 0.2186, Val Acc: 97.08%\n",
      "Epoch 15, Train Loss: 0.0933, Train Acc: 99.79%, Val Loss: 0.1979, Val Acc: 95.83%\n",
      "Epoch 16, Train Loss: 0.0701, Train Acc: 100.00%, Val Loss: 0.1608, Val Acc: 96.25%\n",
      "Epoch 17, Train Loss: 0.0556, Train Acc: 100.00%, Val Loss: 0.1449, Val Acc: 96.25%\n",
      "Epoch 18, Train Loss: 0.0451, Train Acc: 100.00%, Val Loss: 0.1324, Val Acc: 96.67%\n",
      "Epoch 19, Train Loss: 0.0377, Train Acc: 100.00%, Val Loss: 0.1223, Val Acc: 96.67%\n",
      "Epoch 20, Train Loss: 0.0322, Train Acc: 100.00%, Val Loss: 0.1168, Val Acc: 97.08%\n",
      "Epoch 21, Train Loss: 0.0279, Train Acc: 100.00%, Val Loss: 0.1127, Val Acc: 97.08%\n",
      "Epoch 22, Train Loss: 0.0246, Train Acc: 100.00%, Val Loss: 0.1109, Val Acc: 97.08%\n",
      "Epoch 23, Train Loss: 0.0219, Train Acc: 100.00%, Val Loss: 0.1076, Val Acc: 97.08%\n",
      "Epoch 24, Train Loss: 0.0197, Train Acc: 100.00%, Val Loss: 0.1031, Val Acc: 97.08%\n",
      "Epoch 25, Train Loss: 0.0179, Train Acc: 100.00%, Val Loss: 0.1006, Val Acc: 97.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------\n",
    "# 9. Training and Evaluation\n",
    "# ----------------------------\n",
    "\n",
    "# Split dataset into train and validation\n",
    "full_dataset = EarlyFusionDataset(speech_df, text_df)\n",
    "train_indices, val_indices = train_test_split(list(range(len(full_dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "train_subset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "val_subset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyFusionLSTM(num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (preds == batch_y).sum().item()\n",
    "            total_samples += batch_y.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Training loop with metrics\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        total_correct += (preds == batch_y).sum().item()\n",
    "        total_samples += batch_y.size(0)\n",
    "\n",
    "    train_acc = total_correct / total_samples\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    val_acc, val_loss = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_acc*100:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Acc: {val_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
